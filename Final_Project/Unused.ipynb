{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling Min-Max Normalization\n",
    "\n",
    "    def StandardScaler(self):\n",
    "\n",
    "        # Evaluate the mean and variance of all inputs\n",
    "\n",
    "        all_input_data = []\n",
    "        for i in range(len(self._RawCleanInputData)):\n",
    "            for j in range(len(self._RawCleanInputData[0])):\n",
    "                all_input_data.append(self._RawCleanInputData[i][j])\n",
    "\n",
    "        # Standard Scaler = x(i) - mean / S.D -> S.D = Variance**2\n",
    "\n",
    "        mean = statistics.mean(all_input_data)\n",
    "\n",
    "        stdev = statistics.stdev(all_input_data)\n",
    "\n",
    "        print(\"Mean : \" , mean)\n",
    "        print(\"S.D. : \" , stdev)\n",
    "\n",
    "        Scaled_Train_Data = []\n",
    "        for i in range(len(self._RawCleanInputData)):\n",
    "\n",
    "            scaled_data = []\n",
    "            for j in range(len(self._RawCleanInputData[0])):\n",
    "                newScale = (self._RawCleanInputData[i][j] - mean) / stdev\n",
    "                scaled_data.append(newScale)\n",
    "\n",
    "            Scaled_Train_Data.append(scaled_data)\n",
    "        \n",
    "        # List Concatetrating\n",
    "\n",
    "        for i in range(len(Scaled_Train_Data)):\n",
    "            Scaled_Train_Data[i] = Scaled_Train_Data[i] + [ self._RawCleanTargetData[i] ]\n",
    "\n",
    "        self._Scaled_Data = Scaled_Train_Data\n",
    "\n",
    "        # print(self._Scaled_Data)\n",
    "        # You can shuffle there after sorting\n",
    "        self._ScaledTrainData = []\n",
    "        self._ScaledTargetData = []\n",
    "\n",
    "        for column in self._Scaled_Data:\n",
    "            self._ScaledTrainData.append(column[:-1])\n",
    "            self._ScaledTargetData.append(column[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def MinMax_Normalization(self):\n",
    "        Scaled_Train_Data = []\n",
    "        for column in self._RawCleanInputData:\n",
    "            scaled_data = []\n",
    "            min_vals = min(column)\n",
    "            max_vals = max(column)\n",
    "            for value in column:\n",
    "                newScale = (value - min_vals) / (max_vals - min_vals)\n",
    "                scaled_data.append(newScale)\n",
    "\n",
    "            Scaled_Train_Data.append(scaled_data)\n",
    "\n",
    "        # List Concatetrating\n",
    "\n",
    "        for i in range(len(Scaled_Train_Data)):\n",
    "            Scaled_Train_Data[i] = Scaled_Train_Data[i] + [self._RawCleanTargetData[i]]\n",
    "\n",
    "        self._Scaled_Data = Scaled_Train_Data\n",
    "\n",
    "        # You can shuffle there after sorting\n",
    "\n",
    "        self._ScaledTrainData = []\n",
    "        self._ScaledTargetData = []\n",
    "\n",
    "        for column in self._Scaled_Data:\n",
    "            self._ScaledTrainData.append(column[:-1])\n",
    "            self._ScaledTargetData.append(column[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #Xavier/Glorot Random weights of Normal Distribution\n",
    "        # Xavier Initialization the mean will be 0 and s.d. will be \n",
    "        self._weights_input_hidden = Matrix(self._NumInput, self._NumHidden)\n",
    "        for i in range(self._NumInput):\n",
    "            for j in range(self._NumHidden):\n",
    "                sd = math.sqrt(2 / (self._NumInput + self._NumHidden))\n",
    "                self._weights_input_hidden[i, j] = random.normalvariate(0.0, sd)\n",
    "\n",
    "        # # Random weights between hidden and output\n",
    "        self._weights_hidden_output = Matrix(self._NumHidden, self._NumOutput)\n",
    "        for i in range(self._NumHidden):\n",
    "            for j in range(self._NumOutput):\n",
    "                sd = math.sqrt(2 / (self._NumHidden + self._NumOutput))\n",
    "                self._weights_hidden_output[i, j] = random.normalvariate(0.0, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # L2 regularization term for hidden to output weights\n",
    "                l2_hidden_output = self._weights_hidden_output.scaleBy(lmbda)\n",
    "\n",
    "                # L2 regularization term for input to hidden weights\n",
    "                l2_input_hidden = self._weights_input_hidden.scaleBy(lmbda)\n",
    "\n",
    "                # Update weights with regularization terms\n",
    "                self._weights_hidden_output = self._weights_hidden_output - (\n",
    "                    Error_wrt_weights_hidden_output.scaleBy(alpha) + l2_hidden_output\n",
    "                )\n",
    "                self._weights_input_hidden = self._weights_input_hidden - (\n",
    "                    Error_wrt_weights_input_hidden.scaleBy(alpha) + l2_input_hidden\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Initialize Adam optimizer parameters\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.999\n",
    "        epsilon = 1e-8\n",
    "\n",
    "        m_weights_input_hidden = Matrix(self._NumInput, self._NumHidden)\n",
    "        m_weights_hidden_output = Matrix(self._NumHidden, self._NumOutput)\n",
    "\n",
    "        m_weights_input_hidden.clear(0.0)\n",
    "        m_weights_hidden_output.clear(0.0)\n",
    "\n",
    "        v_weights_input_hidden = Matrix(self._NumInput, self._NumHidden)\n",
    "        v_weights_hidden_output = Matrix(self._NumHidden, self._NumOutput)\n",
    "\n",
    "        v_weights_input_hidden.clear(0.0)\n",
    "        v_weights_hidden_output.clear(0.0)\n",
    "\n",
    "\n",
    "                for start in range(0, self._NumTrain, batch_size):\n",
    "                end = start + batch_size\n",
    "                batch_indices = Train_seq[start:end]\n",
    "\n",
    "                # Shuffle batch indices\n",
    "\n",
    "                random.shuffle(batch_indices)\n",
    "\n",
    "                # Initialize Adam gradients\n",
    "                m_weights_input_hidden.clear(0.0)\n",
    "                m_weights_hidden_output.clear(0.0)\n",
    "                v_weights_input_hidden.clear(0.0)\n",
    "                v_weights_hidden_output.clear(0.0)\n",
    "\n",
    "\n",
    "                   # Update Adam gradients\n",
    "                    m_weights_input_hidden = (m_weights_input_hidden.scaleBy(beta1)) + (Error_wrt_weights_input_hidden.scaleBy(1 - beta1))\n",
    "                    m_weights_hidden_output = (m_weights_hidden_output.scaleBy(beta1)) + (Error_wrt_weights_hidden_output.scaleBy(1 - beta1))\n",
    "\n",
    "                    v_weights_input_hidden = (v_weights_input_hidden.scaleBy(beta2)) + (Error_wrt_weights_input_hidden.square().scaleBy(1 - beta2))\n",
    "                    v_weights_hidden_output = (v_weights_hidden_output.scaleBy(beta2)) + (Error_wrt_weights_hidden_output.square().scaleBy(1 - beta2))\n",
    "\n",
    "                    m_weights_input_hidden_hat = (m_weights_input_hidden).divideby(1 - beta1 ** (epoch + 1))\n",
    "                    m_weights_hidden_output_hat = (m_weights_hidden_output).divideby(1 - beta1 ** (epoch + 1))\n",
    "\n",
    "                    v_weights_input_hidden_hat = (v_weights_input_hidden).scaleBy( 1 / (1 - beta2 ** (epoch + 1)))\n",
    "                    v_weights_hidden_output_hat = (v_weights_hidden_output).scaleBy( 1 / (1 - beta2 ** (epoch + 1)))\n",
    "\n",
    "                    \n",
    "\n",
    "                    # Update weights with Adam optimizer\n",
    "                    self._weights_input_hidden = self._weights_input_hidden - ((v_weights_input_hidden_hat.sqrt().plus(epsilon)).dividing(alpha)) * m_weights_input_hidden_hat\n",
    "                    self._weights_hidden_output = self._weights_hidden_output - ((v_weights_hidden_output_hat.sqrt().plus(epsilon)).dividing(alpha)) * m_weights_hidden_output_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def plus(self, number):\n",
    "        newMatrix = Matrix(self.numRows(), self.numCols())\n",
    "        for i in range(self.numRows()):\n",
    "            for j in range(self.numCols()):\n",
    "                newMatrix[i,j] = self[i,j] + number\n",
    "        return newMatrix\n",
    "    \n",
    "    def divideby(self, number):\n",
    "        newMatrix = Matrix(self.numRows(), self.numCols())\n",
    "        for i in range(self.numRows()):\n",
    "            for j in range(self.numCols()):\n",
    "                newMatrix[i,j] = self[i,j] / number\n",
    "        return newMatrix\n",
    "    \n",
    "    def dividing(self , number):\n",
    "        newMatrix = Matrix(self.numRows(), self.numCols())\n",
    "        for i in range(self.numRows()):\n",
    "            for j in range(self.numCols()):\n",
    "                newMatrix[i,j] = number / self[i,j] \n",
    "        return newMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Argmax\n",
    "    def argmax_zero_axis(self):\n",
    "\n",
    "        ''' \n",
    "            Input :\n",
    "            [ [0... 30],\n",
    "              [0... 30],\n",
    "              [1... 30]\n",
    "            ]\n",
    "            แนวตั้งจะแทน ตัวข้อมูลนึง เช่น 001 , 010 , 100\n",
    "        '''\n",
    "        index = []\n",
    "        print(self)\n",
    "        for j in range(self.numCols()):\n",
    "\n",
    "            # กำหนดให้ตัวแถวแรกเป็น max_value\n",
    "            max_value = self[0, j]\n",
    "            max_index = 0\n",
    "            for i in range(self.numRows()):\n",
    "                print(self[i,j])\n",
    "                if max_value < self[i, j]:\n",
    "                    max_value = self[i,j]\n",
    "                    max_index = i\n",
    "            else:\n",
    "                index.append(max_index)\n",
    "\n",
    "        return index"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
